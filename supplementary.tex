\documentclass[10pt,UKenglish]{article}
\usepackage[T1]{fontenc}
\usepackage{fouriernc}
\usepackage[latin9]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose}
\pagestyle{plain}
\usepackage{babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{setspace}
\onehalfspacing
\usepackage{siunitx}
\usepackage{microtype}
\usepackage{nicefrac}
\usepackage{subfigure}
\usepackage[unicode=true, pdfusetitle, bookmarks=true, bookmarksnumbered=false, bookmarksopen=false, breaklinks=false, pdfborder={0 0 1}, backref=false, colorlinks=false]{hyperref}

\begin{document}

\title{Supplementary theory}
\author{Gen Zhang}
 
\maketitle

\renewcommand{\thesection}{S\arabic{section}}
\numberwithin{equation}{subsection}

\section{Bayesian analysis of clone fate data}

The stochastic fate model 
\begin{align}
A &\overset{\lambda}{\longmapsto} \begin{cases}
AA & r \\
AB & 1-2r \\
BB & r\end{cases}, & B &\overset{\gamma}{\longmapsto} \emptyset,
\label{eq:basal-model}
\end{align}
has three fundamental parameters. $\lambda$ may be directly measured from observation of cycling rate; $\rho$ may be measured from Ki67 expression; and $\tau = \rho/r\lambda$ is directly measurable from the measured clone size distribution, which then gives $r$. However, if we can obtain fate data \emph{which also tracks suprabasal cells}, then it is possible to directly determine all parameter from the clone size distribution. Simply fitting the parameters to a given set of data can be difficult, and fail to fully express the confidence in the fitted parameters. As such, we proceed more carefully and fully via Bayesian analysis. In addition, such an analysis would be independent of any biological assumptions such as whether Ki67 is a reliable marker for proliferation.

\subsection{Clone fate with suprabasal cells}

Bayes' theorem gives the \emph{posterior distribution} of the parameters $\theta$ as a result of some observations $O$: $$p(\theta|O) = \frac{p(O|\theta)}{p(O)} p(\theta).$$ The factor of $p(O)$ acts as a \emph{normalisation} to make the left-hand side a proper probability distribution and so is biologically uninteresting. 

The \emph{likelihood} $p(O|\theta)$ depends fundamentally on the predicted clone size distributions $P_{mn}$ (see below, section \ref{sec:p-mn-calculation}). The observations $O$ are a set of cohorts $O_t = \{(m,n)\}$ with $m$ basal cells and $n$ suprabasal cells seen at a time $t$ after induction. We assume that the induction probability is sufficiently low that the initial conditions are essentially just single cell clones. We can filter out induction of suprabasal cells by conditioning $P_{mn}$ on $m \ge 1$, i.e. \emph{floating clones}. Even so, we have an unknown chance of inducing a terminally differentiated cell in the basal layer; we do not want to make extraneous assumptions about induction rates, and filter out such data by conditioning on clones of size 2 or above, i.e. $m+n \ge 2$. The latter criterion also excludes from consideration extinct clones, which are by definition unobservable. As such, we define the \emph{observable clone distribution} $$P^\textrm{obs.}_{mn} = \frac{P_{mn}}{1 - P_{00} - P_{10} - \sum_j P_{0j}}.$$ Now given that the observation $O_t$ is filtered as above, we can compute the likelihood: $$p(O_t|\theta) = \prod_{(m,n) \in O_t} P^\textrm{obs.}_{mn}(t).$$

The only ingredient remaining is the \emph{prior distribution} $p(\theta)$. To be completely rigorous, we should pick it to be a maximum entropy distribution over the parameter space $\theta$ <jaynes>. In this case that means a uniform distribution in $\rho$ and $r$, and (an improper distribution) log-uniform in $\lambda$: $p(\theta) \propto 1/\lambda$. <maybe the following sentences are redundant> However, we will be working with observation sets of several hundred, which makes the likelihood sharply peaked in a small region, and unless the prior changes significantly over this region, it does not really matter what prior is chosen. For this work, uniform distributions over some bounded region was chosen.

Multiple time points can be combined by simply multiplying the likelihood functions together, since by the very nature of cohort studies there are no correlations between different observations at different times.

<translucent blobs> shows a typical example of the inference. The posterior distribution is well-localised distribution, resembling a rugby ball. <defer discussion of what the probabilities mean until later>

\subsection{\label{sec:p-mn-calculation}Clone size distributions with suprabasal cells}

The central prediction of the theory is a distribution $P_{mn}(t)$, the probability of a clone having $m$ basal cells and $n$ suprabasal cells at time $t$ after induction. Since we are tracking suprabasal cells, we will modify the stochastic model \ref{eq:basal-model}:
\begin{equation*}
B \overset{\gamma}{\longmapsto} C,
\end{equation*}
where suprabasal cells are represented as $C$.

Whilst we cannot experimentally distinguish between proliferating CP cells ($A$) and terminally differentiated cells in the basal layer ($B$), it is necessary to do so mathematically as they produce entirely different progeny trees. Thus we will work with the finer grained distribution $P_{m_A m_B n}$ which is related $$P_{mn} = \sum_{m_A + m_B = m} P_{m_A m_B n}.$$ Since this model is Markovian, we can write down the master equation <> which is an infinite set of first order differential equations: 
\begin{equation}
\frac{dP_{m_A m_B n}}{dt} = \sum_{m_A^\prime m_B^\prime n^\prime} T_{m_A m_B n; m_A^\prime m_B^\prime n^\prime} P_{m_A^\prime m_B^\prime n^\prime}. \label{eq:infinite-master}
\end{equation}

The model <> has a special property: the number of cells in a clone can never decrease. This means that $P_{m_A m_B n}(t)$ can only depend on the probabilities of clones with the same or fewer total cells at earlier times. Thus if we only care about clones up to a certain size we can truncate the infinite set $P_{m_A m_B n}$ to a finite one, and package them up into a vector $\mathbf P$. At the same time, only a finite number of elements of $T$ will be needed, and moving them into a matrix $\mathbf T$ allows equation \eqref{eq:infinite-master} to be written compactly as $$\frac{d\mathbf P}{dt} = \mathbf{T P}.$$ This is then a standard differential equation, whose solution is a matrix exponential $$\mathbf P = \exp(\mathbf T t) \mathbf P_0,$$ where $\mathbf P_0$ is the initial condition, i.e. one type $A$ cell.

\subsection{\label{sec:ball-plane}Consistency and improvement with basal statistics}

The need to count suprabasal cells limits the scope of the experiment, as eventually shedding becomes a serious effect, and its statistical effects are likely to be environmentally dominated. Counting basal statistics only, it becomes possible to extend the experiment to longer time scales, and provides both a consistency check of the methodology and also improves the inference accuracy. Whilst it would be straightforward to extract $\tau = \rho/r\lambda$ as shown in <>, it is also worthwhile to run a full-scale Bayesian analysis.

Fundamentally, there is very little change in the procedure described above. The main differences are:

\begin{itemize}
\item The branching model <> does not enjoy the triangular structure which allowed the probabilities to be computed simply via a matrix exponential. The basal distributions $P_m$ are best computed via generating function methods, e.g. <tedious paper; maybe there should be a section here to explain how to do it?>
\item The posterior distribution should now be expected to be a hyperbolic sheet in $(\rho, r, \lambda)$ space, along some definite $\tau$. Since this distribution is not particularly well localised, a true prior should be used. Specifically, one which is log-uniform in $\lambda$.
\end{itemize}

Consistency between basal and basal-plus-suprabasal statistics manifest as non-trivial overlaps of significant parts of the respective posterior distributions (see figure <>). These estimates may then be combined by the usual multiplication of likelihoods (figure <>, main text).

\subsection{Meaning of posterior probabilities}

It is important to be clear about what the 95\% confidence region in figure <> means. The exact statement is that \emph{given the correctness of the underlying model, there is only a 1 in 20 chance that the data collected is perverse to the extent that the true parameters of the model lie outside of the region}.

<inference of MC-generated data; shows spread in inferred ball locations>

Although the posterior distribution is nicely peaked, it would be a mistake to think that the true parameters are more likely to be at the most probable value, as opposed to some definite distance away from the peak. This can be clearly seen in figure <> above, where the true parameters are actually never very close to the centres of the confidence regions. This can be understood very simply as a consequence of multi-dimensional distributions. For example, if we had a three-dimensional Gaussian $$p(\mathbf{r}) \propto \exp(-|\mathbf r|^2),$$ the expectation $\left\langle \mathbf |\mathbf r| \right\rangle > 0$ and is in fact of the order of the standard deviation. In section \ref{sec:ball-plane}, when we look for consistency against long time course basal statistics, we should not be surprised that the hyperbolic sheet does not exactly intersect the centre of the ``rugby ball''.

<need to be more focused>

\section{Replenished subcritical dynamics}

<argument as to why we can concentrate on S-CP; ignore fluctuations in $\rho$>

\subsection{Subcritical CP dynamics}

<exact solution to the subcritical CP problem>

\subsection{Stem supported clones}

<convolution to get the generating function for stem supported clones>

\subsection{Mean clone size evolution}

<show that the mean clone size would eventually plateau, but only after a long time; bounds stem turn-over rates>

\subsection{Basal distribution evolution}

<show that the stem compartment makes no difference to the clone size distributions, modulo minor shifts in parameters>

\end{document}
